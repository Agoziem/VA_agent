{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e18efe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# llm = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af27cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearch(max_results=5)\n",
    "tools = [search_tool]\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb46d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30864fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "\n",
    "\n",
    "async def model(state: State) -> State:\n",
    "    \"\"\"\n",
    "    Model function that processes the state and returns it.\n",
    "    \"\"\"\n",
    "    # Convert messages to a format suitable for the LLM\n",
    "    messages = state['messages']\n",
    "\n",
    "    # Invoke the LLM with the messages\n",
    "    response = await llm_with_tools.ainvoke(messages)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "\n",
    "async def tool_router(state: State):\n",
    "    \"\"\"\n",
    "    Tool router function that processes the state and returns it.\n",
    "    \"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else None\n",
    "    # Check if the last message is a ToolMessage\n",
    "    if last_message and hasattr(last_message, 'tool_calls') and len(last_message.tool_calls) > 0:\n",
    "        return \"tool_node\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "\n",
    "async def tool_node(state: State):\n",
    "    \"\"\"\n",
    "    Tool node function that processes the state and returns it.\n",
    "    \"\"\"\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    if not tool_calls:\n",
    "        return state\n",
    "    # Process each tool call\n",
    "    tool_messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "\n",
    "        if tool_name == \"tavily_search\":\n",
    "            # Call the Tavily search tool\n",
    "            search_results = await search_tool.ainvoke(tool_args)\n",
    "            print(f\"Search results: {search_results}\")\n",
    "            # Create a ToolMessage with the search results\n",
    "            tool_message = ToolMessage(\n",
    "                content=str(search_results),\n",
    "                name=tool_name,\n",
    "                tool_call_id=tool_id,\n",
    "            )\n",
    "            tool_messages.append(tool_message)\n",
    "    return {\n",
    "        \"messages\": tool_messages\n",
    "    }\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"model\", model)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "graph_builder.set_entry_point(\"model\")\n",
    "graph_builder.add_conditional_edges(\"model\", tool_router, path_map={\n",
    "    \"tool_node\": \"tool_node\",\n",
    "    END: END\n",
    "})\n",
    "graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23939cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object Pregel.ainvoke at 0x7f72d71281b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "thread_config = RunnableConfig(\n",
    "    {\"configurable\": {\n",
    "        \"thread_id\": 11,\n",
    "    }}\n",
    ")\n",
    "\n",
    "response = graph.ainvoke({\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"what are the top headlines in Nigeria News today\"),\n",
    "    ]\n",
    "}, config=thread_config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b299ea1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='what are the top headlines in Nigeria News today ', additional_kwargs={}, response_metadata={})]}}, 'name': 'LangGraph', 'tags': [], 'run_id': '01511a0c-0702-48f1-a429-f17dfb739701', 'metadata': {'thread_id': 15}, 'parent_ids': []}\n",
      "{'event': 'on_chain_start', 'data': {'input': {'messages': [HumanMessage(content='what are the top headlines in Nigeria News today ', additional_kwargs={}, response_metadata={}, id='6c8ce657-963a-4154-b236-3720b576fc0d')]}}, 'name': 'model', 'tags': ['graph:step:1'], 'run_id': '1bf5f369-3b93-4295-ba2f-f71af546d8c9', 'metadata': {'thread_id': 15, 'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:7c9f6a59-c250-cd06-78cd-0740d3de2587'}, 'parent_ids': ['01511a0c-0702-48f1-a429-f17dfb739701']}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='what are the top headlines in Nigeria News today ', additional_kwargs={}, response_metadata={}, id='6c8ce657-963a-4154-b236-3720b576fc0d')]]}}, 'name': 'ChatGoogleGenerativeAI', 'tags': ['seq:step:1'], 'run_id': '341c95ee-9a3b-4478-b9a7-ef4461c8dbe7', 'metadata': {'thread_id': 15, 'langgraph_step': 1, 'langgraph_node': 'model', 'langgraph_triggers': ('branch:to:model',), 'langgraph_path': ('__pregel_pull', 'model'), 'langgraph_checkpoint_ns': 'model:7c9f6a59-c250-cd06-78cd-0740d3de2587', 'checkpoint_ns': 'model:7c9f6a59-c250-cd06-78cd-0740d3de2587', 'ls_provider': 'google_genai', 'ls_model_name': 'gemini-2.0-flash', 'ls_model_type': 'chat', 'ls_temperature': 0.7}, 'parent_ids': ['01511a0c-0702-48f1-a429-f17dfb739701', '1bf5f369-3b93-4295-ba2f-f71af546d8c9']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get info from https://api.smith.langchain.com: LangSmithConnectionError('Connection error caused failure to GET /info in LangSmith API. Please confirm your internet connection. ConnectionError(MaxRetryError(\\'HTTPSConnectionPool(host=\\\\\\'api.smith.langchain.com\\\\\\', port=443): Max retries exceeded with url: /info (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host=\\\\\\'api.smith.langchain.com\\\\\\', port=443): Read timed out. (read timeout=10.0)\"))\\'))\\nContent-Length: None\\nAPI Key: lsv2_********************************************77')\n"
     ]
    }
   ],
   "source": [
    "thread_config = RunnableConfig(\n",
    "    {\"configurable\": {\n",
    "        \"thread_id\": 15,\n",
    "    }}\n",
    ")\n",
    "\n",
    "events = graph.astream_events({\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"what are the top headlines in Nigeria News today \"),\n",
    "    ]\n",
    "}, config=thread_config, version=\"v2\")\n",
    "\n",
    "async for event in events:\n",
    "    print(event)  # Print the event for debugging purposes\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        if \"chunk\" in event[\"data\"]:\n",
    "            # Print the content of the chunk\n",
    "            print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
